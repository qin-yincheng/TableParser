# TableParser ç³»ç»Ÿè¯¦ç»†è¯´æ˜æ–‡æ¡£

## ğŸ“‹ ç›®å½•
1. [ç³»ç»Ÿæ¶æ„æ¦‚è¿°](#ç³»ç»Ÿæ¶æ„æ¦‚è¿°)
2. [MainProcessor æ ¸å¿ƒæµç¨‹](#mainprocessor-æ ¸å¿ƒæµç¨‹)
3. [é…ç½®è¯¦è§£](#é…ç½®è¯¦è§£)
4. [QueryService åŠŸèƒ½è¯´æ˜](#queryservice-åŠŸèƒ½è¯´æ˜)
5. [QAService åŠŸèƒ½è¯´æ˜](#qaservice-åŠŸèƒ½è¯´æ˜)
6. [ä½¿ç”¨ç¤ºä¾‹](#ä½¿ç”¨ç¤ºä¾‹)
7. [éƒ¨ç½²æŒ‡å—](#éƒ¨ç½²æŒ‡å—)

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„æ¦‚è¿°

TableParser æ˜¯ä¸€ä¸ªåŸºäº RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰çš„æ™ºèƒ½æ–‡æ¡£è§£æç³»ç»Ÿï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹æ ¸å¿ƒç»„ä»¶ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æ–‡æ¡£è§£æå±‚     â”‚    â”‚   è¯­ä¹‰å¢å¼ºå±‚     â”‚    â”‚   å‘é‡åŒ–å­˜å‚¨å±‚   â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ DOC/DOCX      â”‚â”€â”€â”€â–¶â”‚ â€¢ LLM å¢å¼º      â”‚â”€â”€â”€â–¶â”‚ â€¢ å‘é‡åµŒå…¥      â”‚
â”‚ â€¢ XLSX          â”‚    â”‚ â€¢ è¯­ä¹‰æè¿°      â”‚    â”‚ â€¢ Weaviate      â”‚
â”‚ â€¢ è¡¨æ ¼è¯†åˆ«      â”‚    â”‚ â€¢ å…³é”®è¯æå–    â”‚    â”‚ â€¢ çŸ¥è¯†åº“ç®¡ç†    â”‚
â”‚ â€¢ æ ¼å¼é…ç½®      â”‚    â”‚ â€¢ ä¸Šä¸‹æ–‡æ„ŸçŸ¥    â”‚    â”‚ â€¢ æ‰¹é‡æ“ä½œ      â”‚
â”‚ â€¢ åˆå¹¶å•å…ƒæ ¼    â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ å¤šçº§è¡¨å¤´      â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   æ™ºèƒ½é—®ç­”å±‚     â”‚
                       â”‚                 â”‚
                       â”‚ â€¢ è¯­ä¹‰æ£€ç´¢      â”‚
                       â”‚ â€¢ ä¸Šä¸‹æ–‡é—®ç­”    â”‚
                       â”‚ â€¢ å¤šè½®å¯¹è¯      â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ MainProcessor æ ¸å¿ƒæµç¨‹

### å…¥å£ä¸å‡ºå£

#### å…¥å£å‡½æ•°
```python
# å•ä¸ªæ–‡æ¡£å¤„ç†
async def process_single_document(file_path: str, kb_id: int) -> Dict[str, Any]

# æ‰¹é‡æ–‡æ¡£å¤„ç†
async def process_multiple_documents(file_paths: List[str], kb_id: int) -> List[Dict[str, Any]]
```

#### å‡ºå£æ•°æ®ç»“æ„
```python
{
    "success": True/False,
    "file_path": "æ–‡æ¡£è·¯å¾„",
    "total_chunks": åˆ†å—æ€»æ•°,
    "successful_vectors": æˆåŠŸå‘é‡åŒ–æ•°é‡,
    "failed_vectors": å¤±è´¥å‘é‡åŒ–æ•°é‡,
    "stored_count": æˆåŠŸå­˜å‚¨æ•°é‡,
    "chunks": [åˆ†å—åˆ—è¡¨],
    "error": "é”™è¯¯ä¿¡æ¯"  # ä»…åœ¨å¤±è´¥æ—¶
}
```

### å¤„ç†æµç¨‹

1. **æ–‡æ¡£è§£æ** â†’ 2. **å‘é‡åµŒå…¥** â†’ 3. **å‘é‡å­˜å‚¨**

#### 1. æ–‡æ¡£è§£æé˜¶æ®µ
- æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©è§£æå™¨ï¼ˆDOC/DOCX æˆ– XLSXï¼‰ï¼Œxlsä¸æ”¯æŒã€‚
- è§£ææ–‡æ¡£å†…å®¹ï¼Œç”Ÿæˆç»“æ„åŒ–åˆ†å—
- æ”¯æŒæ–‡æœ¬æ®µè½å’Œè¡¨æ ¼çš„æ™ºèƒ½åˆ†å—

#### 2. å‘é‡åµŒå…¥é˜¶æ®µ
- ä½¿ç”¨æ™ºæ™®AIç”Ÿæˆè¯­ä¹‰å‘é‡
- æ‰¹é‡å¤„ç†æé«˜æ•ˆç‡
- é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

#### 3. å‘é‡å­˜å‚¨é˜¶æ®µ
- å­˜å‚¨åˆ°Weaviateå‘é‡æ•°æ®åº“
- æŒ‰çŸ¥è¯†åº“IDéš”ç¦»æ•°æ®
- æ”¯æŒå…ƒæ•°æ®å­˜å‚¨

---

## âš™ï¸ é…ç½®è¯¦è§£

### 1. LLM é…ç½®

#### ç¯å¢ƒå˜é‡é…ç½®
```bash
# .env æ–‡ä»¶
LLM_BINDING=openai                    # LLMæä¾›å•†
LLM_MODEL=glm-4-plus                 # æ¨¡å‹åç§°
LLM_BINDING_API_KEY=your_api_key     # APIå¯†é’¥
LLM_BINDING_HOST=                     # è‡ªå®šä¹‰ä¸»æœºï¼ˆå¯é€‰ï¼‰
TIMEOUT=60                           # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
TEMPERATURE=0                        # æ¸©åº¦å‚æ•°
MAX_TOKENS=2048                      # æœ€å¤§tokenæ•°
MAX_ASYNC=4                          # æœ€å¤§å¹¶å‘æ•°
ENABLE_LLM_CACHE=false               # æ˜¯å¦å¯ç”¨ç¼“å­˜
ENABLE_LLM_CACHE_FOR_EXTRACT=false  # æ˜¯å¦å¯ç”¨æå–ç¼“å­˜
```

#### ä»£ç é…ç½®
```python
from utils.config import LLM_CONFIG

# é»˜è®¤é…ç½®
LLM_CONFIG = {
    "enable_cache": False,
    "enable_cache_extract": False,
    "timeout": 60,
    "temperature": 0.0,
    "max_async": 4,
    "max_tokens": 2048,
    "binding": "openai",
    "model": "glm-4-plus",
    "host": "",
    "api_key": "your_api_key"
}
```

### 2. åµŒå…¥æ¨¡å‹é…ç½®

#### ç¯å¢ƒå˜é‡é…ç½®
```bash
# .env æ–‡ä»¶
EMBEDDING_BINDING=openai              # åµŒå…¥æ¨¡å‹æä¾›å•†
EMBEDDING_MODEL=embedding-3           # åµŒå…¥æ¨¡å‹åç§°
EMBEDDING_DIM=2048                    # å‘é‡ç»´åº¦
EMBEDDING_BINDING_API_KEY=your_key   # APIå¯†é’¥
EMBEDDING_BINDING_HOST=               # è‡ªå®šä¹‰ä¸»æœºï¼ˆå¯é€‰ï¼‰
```

#### ä»£ç é…ç½®
```python
from utils.config import EMBEDDING_CONFIG

EMBEDDING_CONFIG = {
    "binding": "openai",
    "model": "embedding-3",
    "dim": 2048,
    "api_key": "your_api_key",
    "host": ""
}
```

### 3. Docker é…ç½®

#### docker-compose.yml
```yaml
services:
  weaviate:
    image: semitechnologies/weaviate:latest
    container_name: weaviate
    ports:
      - "8089:8080"     # HTTPç«¯å£æ˜ å°„
      - "50055:50051"   # gRPCç«¯å£æ˜ å°„
    volumes:
      - weaviate_data:/var/lib/weaviate
    environment:
      PERSISTENCE_DATA_PATH: "/var/lib/weaviate"
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: "true"
      # ä½ æ‰“ç®—ç”¨å¤–éƒ¨æ¨¡å‹å‘é‡åŒ–ï¼Œæ‰€ä»¥è¿™ä¸ªä»ç„¶ä¿æŒ none
      DEFAULT_VECTORIZER_MODULE: "none"
      # åŒæ—¶å¯ç”¨ text2vec-transformers å’Œ tokenizer-gse
      ENABLE_MODULES: "text2vec-transformers,tokenizer-gse"
      ENABLE_TOKENIZER_GSE: "true"
      # æŒ‡å‘æ¨ç†æœåŠ¡å®¹å™¨çš„åœ°å€
      TRANSFORMERS_INFERENCE_API: "http://t2v-inference:8080"
      QUERY_DEFAULTS_LIMIT: "25"
      ENABLE_CRON: "false"
      ENABLE_CLUSTER: "false"
      WEAVIATE_HOSTNAME: "0.0.0.0"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/.well-known/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    depends_on:
      - t2v-inference

  t2v-inference:
    image: semitechnologies/transformers-inference:sentence-transformers-multi-qa-distilbert-cos-v1
    container_name: t2v-inference
    environment:
      ENABLE_CUDA: "false"
    restart: on-failure

  console:
    image: semitechnologies/weaviate-console
    container_name: weaviate-console
    ports:
      - "3000:80"    # æ§åˆ¶å°ç«¯å£
    environment:
      WCS_CONSOLE_WEAVIATE_URL: "http://weaviate:8080"
    depends_on:
      - weaviate
    restart: unless-stopped

volumes:
  weaviate_data:
```



### 4. åˆ†ç‰‡é…ç½®

#### config/config.yaml
```yaml
# åˆ†ç‰‡é…ç½®
fragmentation:
  enable: true                    # æ˜¯å¦å¯ç”¨åˆ†ç‰‡åŠŸèƒ½
  max_chunk_size: 500           # æœ€å¤§chunkå¤§å°
  min_fragment_size: 100         # æœ€å°åˆ†ç‰‡å¤§å°
  chunk_overlap: 50             # åˆ†ç‰‡é‡å å¤§å°
  enable_context_rebuild: true   # æ˜¯å¦é‡æ„ä¸Šä¸‹æ–‡

# æ•°æ®åº“é…ç½®
database:
  weaviate:
    host: "localhost"
    port: 8089
    grpc_host: "localhost"
    grpc_port: 50055
    scheme: "http"
    api_key: null
    timeout: [5, 30]
```

#### è¡¨æ ¼å¤„ç†é…ç½®
```python
from parsers.fragment_config import TableProcessingConfig, FragmentConfig

# è¡¨æ ¼æ ¼å¼é…ç½®
table_config = TableProcessingConfig(
    table_format="markdown",           # "html" æˆ– "markdown"
    table_chunking_strategy="full_only"  # "full_only" æˆ– "full_and_rows"
)

# åˆ†ç‰‡é…ç½®
fragment_config = FragmentConfig(
    enable_fragmentation=True,
    max_chunk_size=500,
    min_fragment_size=100,
    chunk_overlap=50,
    enable_context_rebuild=True,
    table_processing=table_config
)
```

---

## ğŸ” QueryService åŠŸèƒ½è¯´æ˜

### ä¸»è¦åŠŸèƒ½

QueryService æä¾›ä¸‰ç§æŸ¥è¯¢æ–¹å¼ï¼šå®é™…ä¸Šä½¿ç”¨query_bysemantic

1. **è¯­ä¹‰ç›¸ä¼¼åº¦æŸ¥è¯¢** (`query_by_semantic`)  çœŸæ­£çš„å…³é”®è¯åŠ å‘é‡æ··åˆæ£€ç´¢
2. **åˆ†å—ç±»å‹è¿‡æ»¤æŸ¥è¯¢** (`query_by_type`)
3. **æ··åˆæŸ¥è¯¢** (`query_hybrid`)

### 1. è¯­ä¹‰ç›¸ä¼¼åº¦æŸ¥è¯¢

#### åŠŸèƒ½æè¿°
åŸºäºå‘é‡ç›¸ä¼¼åº¦çš„æ™ºèƒ½æ£€ç´¢ï¼Œæ”¯æŒæ··åˆæŸ¥è¯¢ï¼ˆæ–‡æœ¬+å‘é‡ï¼‰

#### ä½¿ç”¨ç¤ºä¾‹
```python
from query_service import QueryService

query_service = QueryService()

# åŸºæœ¬æŸ¥è¯¢
result = await query_service.query_by_semantic(
    question="ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
    kb_id=1,
    limit=10,
    similarity_threshold=0.7
)

# è¿”å›ç»“æœ
{
    "success": True,
    "question": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
    "kb_id": 1,
    "total_count": 5,
    "results": [
        {
            "chunk_id": "chunk_001",
            "chunk_type": "text",
            "content": "äººå·¥æ™ºèƒ½æ˜¯...",
            "similarity_score": 0.85,
            "metadata": {...}
        }
    ]
}
```

#### å‚æ•°è¯´æ˜
- `question`: æŸ¥è¯¢é—®é¢˜
- `kb_id`: çŸ¥è¯†åº“ID
- `limit`: è¿”å›ç»“æœæ•°é‡é™åˆ¶
- `similarity_threshold`: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆå¯é€‰ï¼‰

### 2. åˆ†å—ç±»å‹è¿‡æ»¤æŸ¥è¯¢

#### åŠŸèƒ½æè¿°
æ ¹æ®åˆ†å—ç±»å‹è¿›è¡Œè¿‡æ»¤æŸ¥è¯¢ï¼Œæ”¯æŒå¤šç§ç±»å‹ç»„åˆ

#### ä½¿ç”¨ç¤ºä¾‹
```python
# æŸ¥è¯¢æ‰€æœ‰è¡¨æ ¼
result = query_service.query_by_type(
    chunk_types="table_full",
    kb_id=1,
    limit=100
)

# æŸ¥è¯¢å¤šç§ç±»å‹
result = query_service.query_by_type(
    chunk_types=["text", "table_full"],
    kb_id=1,
    limit=50,
    offset=0
)
```

#### æ”¯æŒçš„åˆ†å—ç±»å‹
- `text`: æ–‡æœ¬æ®µè½
- `table_full`: å®Œæ•´è¡¨æ ¼
- `table_row`: è¡¨æ ¼è¡Œ

### 3. æ··åˆæŸ¥è¯¢

#### åŠŸèƒ½æè¿°
å…ˆæŒ‰ç±»å‹è¿‡æ»¤ï¼Œå†æŒ‰è¯­ä¹‰ç›¸ä¼¼åº¦æ’åº

#### ä½¿ç”¨ç¤ºä¾‹
```python
result = await query_service.query_hybrid(
    question="è´¢åŠ¡æ•°æ®",
    chunk_types=["table_full", "table_row"],
    kb_id=1,
    limit=10,
    distance_threshold=0.6
)
```

---

## ğŸ’¬ QAService åŠŸèƒ½è¯´æ˜

### ä¸»è¦åŠŸèƒ½

QAService æä¾›åŸºäºRAGçš„æ™ºèƒ½é—®ç­”åŠŸèƒ½ï¼ŒåŒ…å«ä»¥ä¸‹æ ¸å¿ƒæ­¥éª¤ï¼š

1. **è¯­ä¹‰æ£€ç´¢** â†’ 2. **ç»“æœèåˆ** â†’ 3. **ä¸Šä¸‹æ–‡æ„å»º** â†’ 4. **ç­”æ¡ˆç”Ÿæˆ**

### æ ¸å¿ƒæ–¹æ³•

#### `answer_question`
```python
async def answer_question(
    self, 
    question: str, 
    kb_id: int, 
    limit: int = None
) -> Dict[str, Union[bool, str, List[Dict]]]
```

#### ä½¿ç”¨ç¤ºä¾‹
```python
from qa_service import QAService

qa_service = QAService()

# åŸºæœ¬é—®ç­”
result = await qa_service.answer_question(
    question="ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
    kb_id=1,
    limit=8
)

# è¿”å›ç»“æœ
{
    "success": True,
    "question": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
    "answer": "æ ¹æ®æ–‡æ¡£å†…å®¹ï¼Œäººå·¥æ™ºèƒ½æ˜¯...",
    "sources": [
        {
            "content": "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯...",
            "chunk_type": "text",
            "similarity_score": 0.85,
            "source_info": {...}
        }
    ],
    "metadata": {"total_sources": 5}
}
```

### å†…éƒ¨å·¥ä½œæµç¨‹

#### 1. è¯­ä¹‰æ£€ç´¢ (`_semantic_retrieval`)
- è°ƒç”¨QueryServiceè¿›è¡Œè¯­ä¹‰æ£€ç´¢
- è·å–ç›¸å…³æ–‡æ¡£ç‰‡æ®µ
- æ”¯æŒç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤

#### 2. ç»“æœèåˆ (`_merge_results`)
- å»é‡å¤„ç†
- æŒ‰ç›¸ä¼¼åº¦æ’åº
- ä¿ç•™æœ€ç›¸å…³çš„ç»“æœ

#### 3. ä¸Šä¸‹æ–‡æ„å»º (`_build_context`)
- æ ¼å¼åŒ–æ£€ç´¢ç»“æœ
- æ§åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆæœ€å¤§32768å­—ç¬¦ï¼‰
- æ„å»ºLLMè¾“å…¥ä¸Šä¸‹æ–‡

#### 4. ç­”æ¡ˆç”Ÿæˆ (`_generate_answer`)
- ä½¿ç”¨æ™ºæ™®AIç”Ÿæˆç­”æ¡ˆ
- åŸºäºæ£€ç´¢å†…å®¹å›ç­”
- æä¾›ç­”æ¡ˆæ¥æºä¿¡æ¯

### é…ç½®å‚æ•°

```python
class QAService:
    def __init__(self):
        self.max_context_length = 32768  # ä¸Šä¸‹æ–‡æœ€å¤§é•¿åº¦
        self.max_results = 8             # æœ€å¤§æ£€ç´¢ç»“æœæ•°
```

---

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### 1. å®Œæ•´æ–‡æ¡£å¤„ç†æµç¨‹

```python
import asyncio
from main_processor import process_single_document, process_multiple_documents

async def main():
    # å¤„ç†å•ä¸ªæ–‡æ¡£
    result = await process_single_document(
        file_path="test_data/testData1.docx",
        kb_id=1
    )
    print(f"å¤„ç†ç»“æœ: {result}")
    
    # æ‰¹é‡å¤„ç†æ–‡æ¡£
    file_paths = [
        "test_data/test1.docx",
        "test_data/test2.xlsx"
    ]
    results = await process_multiple_documents(file_paths, kb_id=1)
    for result in results:
        print(f"å¤„ç†ç»“æœ: {result}")

asyncio.run(main())
```

### 2. æ™ºèƒ½é—®ç­”ç¤ºä¾‹

```python
import asyncio
from qa_service import QAService

async def qa_example():
    qa_service = QAService()
    
    # é—®ç­”
    result = await qa_service.answer_question(
        question="ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
        kb_id=1
    )
    
    if result["success"]:
        print(f"é—®é¢˜: {result['question']}")
        print(f"ç­”æ¡ˆ: {result['answer']}")
        print(f"æ¥æºæ•°é‡: {result['metadata']['total_sources']}")
    else:
        print(f"é”™è¯¯: {result['error']}")

asyncio.run(qa_example())
```

### 3. æŸ¥è¯¢æœåŠ¡ç¤ºä¾‹

```python
import asyncio
from query_service import QueryService

async def query_example():
    query_service = QueryService()
    
    # è¯­ä¹‰æŸ¥è¯¢
    semantic_result = await query_service.query_by_semantic(
        question="è´¢åŠ¡æ•°æ®",
        kb_id=1,
        limit=10
    )
    
    # ç±»å‹è¿‡æ»¤æŸ¥è¯¢
    type_result = query_service.query_by_type(
        chunk_types=["table_full"],
        kb_id=1,
        limit=50
    )
    
    # æ··åˆæŸ¥è¯¢
    hybrid_result = await query_service.query_hybrid(
        question="æ”¶å…¥æƒ…å†µ",
        chunk_types=["table_full", "table_row"],
        kb_id=1,
        limit=10
    )

asyncio.run(query_example())
```

### 4. äº¤äº’å¼é—®ç­”æ¼”ç¤º

```python
import asyncio
from tests.qa_demo import QADemo

async def interactive_demo():
    demo = QADemo()
    await demo.interactive_qa()

# è¿è¡Œäº¤äº’å¼é—®ç­”
asyncio.run(interactive_demo())
```

---

## ğŸ³ éƒ¨ç½²æŒ‡å—

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å®‰è£…LibreOfficeï¼ˆç”¨äºDOCæ–‡ä»¶è½¬æ¢ï¼‰
# Windows: ä¸‹è½½å®‰è£…åŒ…
# Linux: sudo apt-get install libreoffice
# macOS: brew install libreoffice
```

### 2. ç¯å¢ƒå˜é‡é…ç½®

```bash
# .env æ–‡ä»¶
ZHIPUAI_API_KEY=your_zhipu_api_key
WEAVIATE_URL=http://localhost:8089

# LLMé…ç½®
LLM_BINDING=openai
LLM_MODEL=glm-4-plus
LLM_BINDING_API_KEY=your_api_key
TIMEOUT=60
TEMPERATURE=0
MAX_TOKENS=2048

# åµŒå…¥æ¨¡å‹é…ç½®
EMBEDDING_BINDING=openai
EMBEDDING_MODEL=embedding-3
EMBEDDING_DIM=2048
EMBEDDING_BINDING_API_KEY=your_api_key
```

### 3. å¯åŠ¨æœåŠ¡

```bash
# å¯åŠ¨Weaviateå‘é‡æ•°æ®åº“
docker-compose up -d

# éªŒè¯æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs weaviate
```

### 4. é…ç½®æ–‡ä»¶

```yaml
# config/config.yaml
database:
  weaviate:
    host: "localhost"
    port: 8089
    grpc_host: "localhost"
    grpc_port: 50055
    scheme: "http"
    api_key: null
    timeout: [5, 30]

fragmentation:
  enable: true
  max_chunk_size: 500
  min_fragment_size: 100
  chunk_overlap: 50
  enable_context_rebuild: true
```

### 5. æµ‹è¯•éƒ¨ç½²

```python
# æµ‹è¯•è¿æ¥
from vector_service import VectorService

vector_service = VectorService()
if vector_service.collection_exists(1):
    print("Weaviateè¿æ¥æˆåŠŸ")
else:
    print("Weaviateè¿æ¥å¤±è´¥")

# æµ‹è¯•æ–‡æ¡£å¤„ç†
from main_processor import process_single_document
import asyncio

async def test_processing():
    result = await process_single_document("test_data/testData1.docx", kb_id=1)
    print(f"æµ‹è¯•ç»“æœ: {result}")

asyncio.run(test_processing())
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ‰¹é‡å¤„ç†ä¼˜åŒ–
- ä½¿ç”¨ `process_multiple_documents` è¿›è¡Œæ‰¹é‡å¤„ç†
- åˆç†è®¾ç½®å¹¶å‘æ•°é‡
- ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µ

### 2. å‘é‡åŒ–ä¼˜åŒ–
- è°ƒæ•´ `max_async` å‚æ•°æ§åˆ¶å¹¶å‘æ•°
- ä½¿ç”¨æ‰¹é‡å‘é‡åŒ–å‡å°‘APIè°ƒç”¨
- å¯ç”¨ç¼“å­˜å‡å°‘é‡å¤è®¡ç®—

### 3. å­˜å‚¨ä¼˜åŒ–
- å®šæœŸæ¸…ç†æ— ç”¨æ•°æ®
- ç›‘æ§Weaviateå­˜å‚¨ç©ºé—´
- åˆç†è®¾ç½®åˆ†ç‰‡å¤§å°

### 4. æŸ¥è¯¢ä¼˜åŒ–
- ä½¿ç”¨åˆé€‚çš„ç›¸ä¼¼åº¦é˜ˆå€¼
- é™åˆ¶è¿”å›ç»“æœæ•°é‡
- åˆ©ç”¨åˆ†å—ç±»å‹è¿‡æ»¤æé«˜æ•ˆç‡

---

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **LibreOfficeæœªå®‰è£…**
   ```bash
   # æ£€æŸ¥å®‰è£…
   libreoffice --version
   
   # å®‰è£…LibreOffice
   # Windows: ä¸‹è½½å®‰è£…åŒ…
   # Linux: sudo apt-get install libreoffice
   # macOS: brew install libreoffice
   ```

2. **Weaviateè¿æ¥å¤±è´¥**
   ```bash
   # æ£€æŸ¥æœåŠ¡çŠ¶æ€
   docker-compose ps
   
   # æŸ¥çœ‹æ—¥å¿—
   docker-compose logs weaviate
   
   # é‡å¯æœåŠ¡
   docker-compose restart weaviate
   ```

3. **APIå¯†é’¥é”™è¯¯**
   ```bash
   # æ£€æŸ¥ç¯å¢ƒå˜é‡
   echo $ZHIPUAI_API_KEY
   
   # é‡æ–°è®¾ç½®
   export ZHIPUAI_API_KEY=your_api_key
   ```

4. **å†…å­˜ä¸è¶³**
   ```yaml
   # è°ƒæ•´åˆ†ç‰‡é…ç½®
   fragmentation:
     max_chunk_size: 300  # å‡å°åˆ†ç‰‡å¤§å°
     chunk_overlap: 30    # å‡å°é‡å 
   ```

---

## ğŸ“ æ€»ç»“

TableParser ç³»ç»Ÿæä¾›äº†å®Œæ•´çš„æ–‡æ¡£è§£æã€å‘é‡åŒ–å’Œæ™ºèƒ½é—®ç­”è§£å†³æ–¹æ¡ˆã€‚é€šè¿‡åˆç†çš„é…ç½®å’Œä¼˜åŒ–ï¼Œå¯ä»¥å®ç°é«˜æ•ˆçš„æ–‡æ¡£å¤„ç†å’Œæ™ºèƒ½æ£€ç´¢åŠŸèƒ½ã€‚

å…³é”®é…ç½®ç‚¹ï¼š
- **LLMé…ç½®**: å½±å“è¯­ä¹‰å¢å¼ºå’Œç­”æ¡ˆç”Ÿæˆè´¨é‡
- **åµŒå…¥æ¨¡å‹é…ç½®**: å½±å“å‘é‡åŒ–æ•ˆæœå’Œæ£€ç´¢ç²¾åº¦
- **åˆ†ç‰‡é…ç½®**: å½±å“å¤„ç†æ•ˆç‡å’Œå­˜å‚¨ç©ºé—´
- **Dockeré…ç½®**: å½±å“æœåŠ¡ç¨³å®šæ€§å’Œæ€§èƒ½

é€šè¿‡æœ¬æ–‡æ¡£çš„æŒ‡å¯¼ï¼Œæ‚¨å¯ä»¥å¿«é€Ÿéƒ¨ç½²å’Œä½¿ç”¨TableParserç³»ç»Ÿï¼Œå®ç°æ™ºèƒ½æ–‡æ¡£å¤„ç†å’Œåˆ†æåŠŸèƒ½ã€‚
