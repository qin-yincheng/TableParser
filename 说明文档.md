# TableParser 系统详细说明文档

## 📋 目录
1. [系统架构概述](#系统架构概述)
2. [MainProcessor 核心流程](#mainprocessor-核心流程)
3. [配置详解](#配置详解)
4. [图片处理详解](#图片处理详解)
5. [QueryService 功能说明](#queryservice-功能说明)
6. [QAService 功能说明](#qaservice-功能说明)
7. [使用示例](#使用示例)
8. [部署指南](#部署指南)
9. [最新更新说明](#最新更新说明)

---

## 🏗️ 系统架构概述

TableParser 是一个基于 RAG（检索增强生成）的智能文档解析系统，主要包含以下核心组件：

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   文档解析层     │    │   语义增强层     │    │   向量化存储层   │
│                 │    │                 │    │                 │
│ • DOC/DOCX      │───▶│ • LLM 增强      │───▶│ • 向量嵌入      │
│ • XLSX          │    │ • 语义描述      │    │ • Weaviate      │
│ • 表格识别      │    │ • 关键词提取    │    │ • 知识库管理    │
│ • 格式配置      │    │ • 上下文感知    │    │ • 批量操作      │
│ • 合并单元格    │    │ • 智能过滤      │    │ • 多粒度存储    │
│ • 多级表头      │    │                 │    │                 │
│ • 图片处理      │    │                 │    │                 │
└─────────────────┘    └─────────────────┘    └─────────────────┘
                                │
                                ▼
                       ┌─────────────────┐
                       │   智能问答层     │
                       │                 │
                       │ • 语义检索      │
                       │ • 上下文问答    │
                       │ • 多轮对话      │
                       │ • 答案追踪      │
                       └─────────────────┘
```

---

## 🔄 MainProcessor 核心流程

### 入口与出口

#### 入口函数
```python
# 单个文档处理
async def process_single_document(file_path: str, kb_id: int) -> Dict[str, Any]

# 批量文档处理
async def process_multiple_documents(file_paths: List[str], kb_id: int) -> List[Dict[str, Any]]
```

#### 出口数据结构
```python
{
    "success": True/False,
    "file_path": "文档路径",
    "total_chunks": 分块总数,
    "successful_vectors": 成功向量化数量,
    "failed_vectors": 失败向量化数量,
    "stored_count": 成功存储数量,
    "chunks": [分块列表],
    "error": "错误信息"  # 仅在失败时
}
```

### 处理流程

1. **文档解析** → 2. **向量嵌入** → 3. **向量存储**

#### 1. 文档解析阶段
- 根据文件扩展名选择解析器（DOC/DOCX 或 XLSX），xls不支持。
- 解析文档内容，生成结构化分块
- 支持文本段落和表格的智能分块
- **新增**：智能文本块过滤，只对分片文本块和表格块进行语义增强

#### 2. 向量嵌入阶段
- 使用智普AI生成语义向量
- 批量处理提高效率
- 错误处理和重试机制
- **注意**：向量库schema中缺少context字段，需要手动添加

#### 3. 向量存储阶段
- 存储到Weaviate向量数据库
- 按知识库ID隔离数据
- 支持元数据存储
- 支持多粒度分块（text、table_full、table_row、image）

---

## ⚙️ 配置详解

### 1. LLM 配置

#### 环境变量配置
```bash
# .env 文件
LLM_BINDING=openai                    # LLM提供商
LLM_MODEL=glm-4-plus                 # 模型名称
LLM_BINDING_API_KEY=your_api_key     # API密钥
LLM_BINDING_HOST=                     # 自定义主机（可选）
TIMEOUT=60                           # 超时时间（秒）
TEMPERATURE=0                        # 温度参数
MAX_TOKENS=2048                      # 最大token数
MAX_ASYNC=4                          # 最大并发数
ENABLE_LLM_CACHE=false               # 是否启用缓存
ENABLE_LLM_CACHE_FOR_EXTRACT=false  # 是否启用提取缓存
```

#### 代码配置
```python
from utils.config import LLM_CONFIG

# 默认配置
LLM_CONFIG = {
    "enable_cache": os.getenv("ENABLE_LLM_CACHE", "false").lower() == "true",
    "enable_cache_extract": os.getenv("ENABLE_LLM_CACHE_FOR_EXTRACT", "false").lower() == "true",
    "timeout": int(os.getenv("TIMEOUT", "60")),
    "temperature": float(os.getenv("TEMPERATURE", "0")),
    "max_async": int(os.getenv("MAX_ASYNC", "4")),
    "max_tokens": int(os.getenv("MAX_TOKENS", "2048")),
    "binding": os.getenv("LLM_BINDING", "openai"),
    "model": os.getenv("LLM_MODEL", "glm-4-plus"),
    "host": os.getenv("LLM_BINDING_HOST", ""),
    "api_key": os.getenv("LLM_BINDING_API_KEY", ""),
}
```

### 2. 嵌入模型配置

#### 环境变量配置
```bash
# .env 文件
EMBEDDING_BINDING=openai              # 嵌入模型提供商
EMBEDDING_MODEL=embedding-3           # 嵌入模型名称
EMBEDDING_DIM=2048                    # 向量维度
EMBEDDING_BINDING_API_KEY=your_key   # API密钥
EMBEDDING_BINDING_HOST=               # 自定义主机（可选）
```

#### 代码配置
```python
from utils.config import EMBEDDING_CONFIG

EMBEDDING_CONFIG = {
    "binding": os.getenv("EMBEDDING_BINDING", "openai"),
    "model": os.getenv("EMBEDDING_MODEL", "embedding-3"),
    "dim": int(os.getenv("EMBEDDING_DIM", "2048")),
    "api_key": os.getenv("EMBEDDING_BINDING_API_KEY", ""),
    "host": os.getenv("EMBEDDING_BINDING_HOST", ""),
}
```

### 3. 视觉模型配置

#### 环境变量配置
```bash
# .env 文件
VISION_MODEL=glm-4v-plus             # 视觉模型名称
VISION_BINDING_API_KEY=your_api_key  # API密钥
VISION_TIMEOUT=60                    # 超时时间
VISION_MAX_CONCURRENT=5              # 最大并发数
VISION_CONTEXT_WINDOW=1              # 上下文窗口
VISION_RETRY_COUNT=3                 # 重试次数
VISION_CACHE_ENABLED=true            # 是否启用缓存
VISION_CACHE_TTL=3600                # 缓存TTL（秒）
```

#### 代码配置
```python
from utils.config import VISION_CONFIG

VISION_CONFIG = {
    "model": os.getenv("VISION_MODEL", "glm-4v-plus"),
    "api_key": os.getenv("VISION_BINDING_API_KEY", ""),
    "timeout": int(os.getenv("VISION_TIMEOUT", "60")),
    "max_concurrent": int(os.getenv("VISION_MAX_CONCURRENT", "5")),
    "context_window": int(os.getenv("VISION_CONTEXT_WINDOW", "1")),
    "retry_count": int(os.getenv("VISION_RETRY_COUNT", "3")),
    "cache_enabled": os.getenv("VISION_CACHE_ENABLED", "true").lower() == "true",
    "cache_ttl": int(os.getenv("VISION_CACHE_TTL", "3600")),
}
```
```

### 3. 视觉模型配置

#### 环境变量配置
```bash
# .env 文件
VISION_MODEL=glm-4v-plus             # 视觉模型名称
VISION_BINDING_API_KEY=your_api_key  # API密钥
VISION_TIMEOUT=60                    # 超时时间
VISION_MAX_CONCURRENT=5              # 最大并发数
VISION_CONTEXT_WINDOW=1              # 上下文窗口
VISION_RETRY_COUNT=3                 # 重试次数
VISION_CACHE_ENABLED=true            # 是否启用缓存
VISION_CACHE_TTL=3600                # 缓存TTL（秒）
```

#### 代码配置
```python
from utils.config import VISION_CONFIG

VISION_CONFIG = {
    "model": os.getenv("VISION_MODEL", "glm-4v-plus"),
    "api_key": os.getenv("VISION_BINDING_API_KEY", ""),
    "timeout": int(os.getenv("VISION_TIMEOUT", "60")),
    "max_concurrent": int(os.getenv("VISION_MAX_CONCURRENT", "5")),
    "context_window": int(os.getenv("VISION_CONTEXT_WINDOW", "1")),
    "retry_count": int(os.getenv("VISION_RETRY_COUNT", "3")),
    "cache_enabled": os.getenv("VISION_CACHE_ENABLED", "true").lower() == "true",
    "cache_ttl": int(os.getenv("VISION_CACHE_TTL", "3600")),
}
```

### 4. Docker 配置

#### docker-compose.yml
```yaml
services:
  weaviate:
    image: semitechnologies/weaviate:latest
    container_name: weaviate
    ports:
      - "8089:8080"     # HTTP端口映射
      - "50055:50051"   # gRPC端口映射
    volumes:
      - weaviate_data:/var/lib/weaviate
    environment:
      PERSISTENCE_DATA_PATH: "/var/lib/weaviate"
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: "true"
      # 使用外部向量生成，保持 none
      DEFAULT_VECTORIZER_MODULE: "none"
      # 启用 tokenizer-gse（中文倒排索引效果更好），同时预留 text2vec-transformers
      ENABLE_MODULES: "text2vec-transformers,tokenizer-gse"
      ENABLE_TOKENIZER_GSE: "true"
      # 指向推理服务容器的地址
      TRANSFORMERS_INFERENCE_API: "http://t2v-inference:8080"
      QUERY_DEFAULTS_LIMIT: "25"
      ENABLE_CRON: "false"
      ENABLE_CLUSTER: "false"
      WEAVIATE_HOSTNAME: "0.0.0.0"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/.well-known/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    depends_on:
      - t2v-inference

  t2v-inference:
    image: semitechnologies/transformers-inference:sentence-transformers-multi-qa-distilbert-cos-v1
    container_name: t2v-inference
    environment:
      ENABLE_CUDA: "false"
    restart: on-failure

  console:
    image: semitechnologies/weaviate-console
    container_name: weaviate-console
    ports:
      - "3000:80"    # 控制台端口
    environment:
      WCS_CONSOLE_WEAVIATE_URL: "http://weaviate:8080"
    depends_on:
      - weaviate
    restart: unless-stopped

volumes:
  weaviate_data:
```

### 5. 分片与图片处理配置

#### config/config.yaml
```yaml
# 分片配置
fragmentation:
  enable: true                    # 是否启用分片功能
  max_chunk_size: 500           # 最大chunk大小
  min_fragment_size: 100         # 最小分片大小
  chunk_overlap: 50             # 分片重叠大小
  enable_context_rebuild: true   # 是否重构上下文

# 数据库配置
database:
  weaviate:
    host: "localhost"
    port: 8089
    grpc_host: "localhost"
    grpc_port: 50055
    scheme: "http"
    api_key: null
    timeout: [5, 30]

# 图片处理
image_processing:
  enabled: true
  storage_path: "storage/images"
  image_position_strategy: "inline"           # inline | placeholder_replace | append_end
  table_image_attach_mode: "separate_block"  # separate_block | merge_into_row | merge_into_table
```

#### 表格处理配置
```python
from parsers.fragment_config import TableProcessingConfig, FragmentConfig

# 表格格式配置
table_config = TableProcessingConfig(
    table_format="markdown",           # "html" 或 "markdown"
    table_chunking_strategy="full_only"  # "full_only" 或 "full_and_rows"
)

# 分片配置
fragment_config = FragmentConfig(
    enable_fragmentation=True,
    max_chunk_size=500,
    min_fragment_size=100,
    chunk_overlap=50,
    enable_context_rebuild=True,
    table_processing=table_config
)
```

---

## 🔍 QueryService 功能说明

### 主要功能

QueryService 提供三种查询方式：

1. **语义相似度查询** (`query_by_semantic`)  基于向量与关键词的混合检索
2. **分块类型过滤查询** (`query_by_type`)
3. **混合查询** (`query_hybrid`)

### 1. 语义相似度查询

#### 功能描述
基于向量相似度的智能检索，支持混合查询（文本+向量）

#### 使用示例
```python
from query_service import QueryService

query_service = QueryService()

# 基本查询
result = await query_service.query_by_semantic(
    question="什么是人工智能？",
    kb_id=1,
    limit=10,
    similarity_threshold=0.7
)

# 返回结果
{
    "success": True,
    "question": "什么是人工智能？",
    "kb_id": 1,
    "total_count": 5,
    "results": [
        {
            "chunk_id": "chunk_001",
            "chunk_type": "text",
            "content": "人工智能是...",
            "similarity_score": 0.85,
            "metadata": {...}
        }
    ]
}
```

#### 参数说明
- `question`: 查询问题
- `kb_id`: 知识库ID
- `limit`: 返回结果数量限制
- `similarity_threshold`: 相似度阈值（可选）

### 2. 分块类型过滤查询

#### 功能描述
根据分块类型进行过滤查询，支持多种类型组合

#### 使用示例
```python
# 查询所有表格
result = query_service.query_by_type(
    chunk_types="table_full",
    kb_id=1,
    limit=100
)

# 查询多种类型
result = query_service.query_by_type(
    chunk_types=["text", "table_full"],
    kb_id=1,
    limit=50,
    offset=0
)
```

#### 支持的分块类型
- `text`: 文本段落
- `table_full`: 完整表格
- `table_row`: 表格行
- `image`: 图片块
- `image`: 图片块

### 3. 混合查询

#### 功能描述
先按类型过滤，再按语义相似度排序

#### 使用示例
```python
result = await query_service.query_hybrid(
    question="财务数据",
    chunk_types=["table_full", "table_row"],
    kb_id=1,
    limit=10,
    distance_threshold=0.6
)
```

---

## 💬 QAService 功能说明

### 主要功能

QAService 提供基于RAG的智能问答功能，包含以下核心步骤：

1. **语义检索** → 2. **结果融合** → 3. **上下文构建** → 4. **答案生成**

### 核心方法

#### `answer_question`
```python
async def answer_question(
    self, 
    question: str, 
    kb_id: int, 
    limit: int = None
) -> Dict[str, Union[bool, str, List[Dict]]]
```

#### 使用示例
```python
import asyncio
from qa_service import QAService

async def main():
    qa_service = QAService()
    result = await qa_service.answer_question(
        question="什么是人工智能？",
        kb_id=1,
        limit=8
    )
    print(result)

asyncio.run(main())
```

### 内部工作流程

#### 1. 语义检索 (`_semantic_retrieval`)
- 调用QueryService进行语义检索
- 获取相关文档片段
- 支持相似度阈值过滤

#### 2. 结果融合 (`_merge_results`)
- 去重处理
- 按相似度排序
- 保留最相关的结果

#### 3. 上下文构建 (`_build_context`)
- 格式化检索结果
- 控制上下文长度（最大32768字符）
- 构建LLM输入上下文

#### 4. 答案生成 (`_generate_answer`)
- 使用智普AI生成答案
- 基于检索内容回答
- 提供答案来源信息

### 配置参数

```python
class QAService:
    def __init__(self):
        self.max_context_length = 32768  # 上下文最大长度
        self.max_results = 8             # 最大检索结果数
```

---

## 🚀 使用示例

### 1. 完整文档处理流程

```python
import asyncio
from main_processor import process_single_document, process_multiple_documents

async def main():
    # 处理单个文档
    result = await process_single_document(
        file_path="test_data/testData1.docx",
        kb_id=1
    )
    print(f"处理结果: {result}")
    
    # 批量处理文档
    file_paths = [
        "test_data/test1.docx",
        "test_data/test2.xlsx"
    ]
    results = await process_multiple_documents(file_paths, kb_id=1)
    for result in results:
        print(f"处理结果: {result}")

asyncio.run(main())
```

### 2. 智能问答示例

```python
import asyncio
from qa_service import QAService

async def qa_example():
    qa_service = QAService()
    result = await qa_service.answer_question(
        question="什么是人工智能？",
        kb_id=1
    )
    print(result)

asyncio.run(qa_example())
```

### 3. 查询服务示例

```python
import asyncio
from query_service import QueryService

async def query_example():
    query_service = QueryService()
    
    # 语义查询
    semantic_result = await query_service.query_by_semantic(
        question="财务数据",
        kb_id=1,
        limit=10
    )
    
    # 类型过滤查询
    type_result = query_service.query_by_type(
        chunk_types=["table_full"],
        kb_id=1,
        limit=50
    )
    
    # 混合查询
    hybrid_result = await query_service.query_hybrid(
        question="收入情况",
        chunk_types=["table_full", "table_row"],
        kb_id=1,
        limit=10
    )

asyncio.run(query_example())
```

### 4. 交互式问答演示

```python
import asyncio
from tests.qa_demo import QADemo

async def interactive_demo():
    demo = QADemo()
    await demo.interactive_qa()

# 运行交互式问答
asyncio.run(interactive_demo())
```

---

## 🖼️ 图片处理详解

本节帮助在"无图片功能"的环境中也能正确接入与禁用图片相关代码，确保主流程不受影响。

### 1. 模块组成与职责

- `parsers/image_processing/image_extractor.py`
  - 定位 Word 段落与表格单元格中的图片（支持 w:drawing 与 VML pict）
  - 基于关系 ID (rel_id) 去重，保存到 `storage/images/<doc_id>/...`
  - 产出标准图片块：
    ```json
    {
      "type": "image",
      "content": "storage/images/<doc_id>/<filename>.png",
      "metadata": {
        "doc_id": "<doc filename>",
        "image_filename": "<filename>",
        "original_filename": "word/media/image1.png",
        "image_index": 0,
        "rel_id": "rId7",
        "processing_status": "pending",
        "container_type": "paragraph | table_cell",
        "paragraph_index": 3,
        "table_id": "table_...",
        "row": 2,
        "col": 1,
        "parent_table_info": "..."
      },
      "context": ""
    }
    ```

- `parsers/image_processing/context_collector.py`
  - 为每一张图片收集临近文本上下文（前后若干文本块）与图片在文档中的位置描述

- `parsers/image_processing/image_analyzer.py`
  - 通过视觉模型生成图片语义：`description/keywords/image_type/context_relation/key_information/searchable_queries`
  - 返回的 `searchable_queries` 仅用于向量化文本拼接，不直接落库

### 2. 在无图片能力环境中如何禁用

有三种层面可控：

- 运行时配置（推荐）
  - 在 `config/config.yaml` 设置：
    ```yaml
    image_processing:
      enabled: false
    ```
  - 效果：解析器不会启用图片模块，文档处理不产出图片块，主流程不受影响

- 环境变量（可选）
  - 不设置 `VISION_BINDING_API_KEY`，系统会捕获异常并自动降级为"禁用图片分析"（提取仍可选择禁用）

- 代码层开关（保底）
  - 在使用 `DocFileParser` 时显式禁用：
    ```python
    from parsers.fragment_config import FragmentConfig
    from utils.config_manager import ConfigManager

    cfg = ConfigManager().get_config()
    cfg.setdefault("image_processing", {})["enabled"] = False
    parser = DocFileParser(fragment_config=FragmentConfig())
    ```

### 3. 与主流程/向量库的对接

- 向量化文本构建（`embedding_service.py`）
  - 对图片块，向量化文本由以下部分拼接：
    - `metadata.description`
    - `metadata.keywords`
    - `metadata.searchable_queries`（最多5条，去重清洗，仅参与向量化，不回写库）
  - 若没有任何分析结果，则退化为使用 `original_filename` 或"图片内容"占位

- 向量库 schema（`vector_service.py` -> `create_collection`）
  - 与图片相关字段：`image_path`, `original_filename`, `image_type`, `context_relation`, `key_information`
  - 关键词类字段落库为逗号分隔字符串，查询返回时再转换为列表

- 存储逻辑
  - 图片块作为普通对象入库：`chunk_type = image`，`content` 存放图片路径
  - 与表格/段落的关联通过 `metadata` 中的 `container_type/table_id/row/col/paragraph_index` 等信息表达

### 4. 图片块的接入与回退策略

- 插入位置策略（`image_position_strategy`）
  - `inline`：在段落/表格解析过程中就地插入图片块（当前默认）
  - `placeholder_replace`：预留占位，后处理时再替换（预留）
  - `append_end`：文档解析完后追加所有图片块（作为回退）

- 表格图片附着模式（`table_image_attach_mode`）
  - `separate_block`：每张图片生成独立图片块并紧随相关表格块之后
  - `merge_into_row`：把图片合并进对应 `table_row` 的 `metadata.embedded_images`
  - `merge_into_table`：把图片合并进 `table_full` 的 `metadata.embedded_images`

### 5. 最小接入指南（无图片环境）

目标：保证你无需任何视觉模型/图片处理依赖，也能运行全链路。

步骤：
1) 在 `config/config.yaml` 中设置：
   ```yaml
   image_processing:
     enabled: false
   ```
2) 不配置 `.env` 的 `VISION_*` 变量
3) 其余文档解析/向量化/问答的功能如常工作，无需改动代码

### 6. 调试与排错

- 路径分隔符规范：图片路径在问答输出时会被统一成正斜杠 `/`
- 失败回退：视觉分析失败不影响主流程，`processing_status` 会标记为 `failed`
- 存储目录：`storage/images/<doc_id>/...`，清理策略由业务自行制定

---

## 🐳 部署指南

### 1. 环境准备

```bash
# 安装依赖
pip install -r requirements.txt

# 安装LibreOffice（用于DOC文件转换）
# Windows: 下载安装包
# Linux: sudo apt-get install libreoffice
# macOS: brew install libreoffice
```

### 2. 环境变量配置

```bash
# .env 文件（示例）

# 大语言模型
LLM_BINDING=openai
LLM_MODEL=glm-4-plus
LLM_BINDING_API_KEY=your_api_key
TIMEOUT=60
TEMPERATURE=0
MAX_TOKENS=2048
MAX_ASYNC=4

# 向量嵌入模型
EMBEDDING_BINDING=openai
EMBEDDING_MODEL=embedding-3
EMBEDDING_DIM=2048
EMBEDDING_BINDING_API_KEY=your_api_key

# 视觉模型（图片理解）
VISION_MODEL=glm-4v-plus
VISION_BINDING_API_KEY=your_api_key
VISION_TIMEOUT=60
VISION_MAX_CONCURRENT=5
VISION_CONTEXT_WINDOW=3
VISION_RETRY_COUNT=3
VISION_CACHE_ENABLED=true
VISION_CACHE_TTL=3600
```

### 3. 启动服务

```bash
# 启动Weaviate向量数据库
docker-compose up -d

# 验证服务状态
docker-compose ps

# 查看日志
docker-compose logs weaviate
```

### 4. 配置文件

```yaml
# config/config.yaml
database:
  weaviate:
    host: "localhost"
    port: 8089
    grpc_host: "localhost"
    grpc_port: 50055
    scheme: "http"
    api_key: null
    timeout: [5, 30]

fragmentation:
  enable: true
  max_chunk_size: 500
  min_fragment_size: 100
  chunk_overlap: 50
  enable_context_rebuild: true
```

### 5. 测试部署

```python
# 测试连接
from vector_service import VectorService

vector_service = VectorService()
if vector_service.collection_exists(1):
    print("Weaviate连接成功")
else:
    print("Weaviate连接失败")

# 测试文档处理
from main_processor import process_single_document
import asyncio

async def test_processing():
    result = await process_single_document("test_data/testData1.docx", kb_id=1)
    print(f"测试结果: {result}")

asyncio.run(test_processing())
```

---

## 📊 性能优化建议

### 1. 批量处理优化
- 使用 `process_multiple_documents` 进行批量处理
- 合理设置并发数量
- 监控内存使用情况

### 2. 向量化优化
- 调整 `max_async` 参数控制并发数
- 使用批量向量化减少API调用
- 启用缓存减少重复计算

### 3. 存储优化
- 定期清理无用数据
- 监控Weaviate存储空间
- 合理设置分片大小

### 4. 查询优化
- 使用合适的相似度阈值
- 限制返回结果数量
- 利用分块类型过滤提高效率

---

## 🔧 故障排除

### 常见问题

1. **LibreOffice未安装**
   ```bash
   # 检查安装
   libreoffice --version
   
   # 安装LibreOffice
   # Windows: 下载安装包
   # Linux: sudo apt-get install libreoffice
   # macOS: brew install libreoffice
   ```

2. **Weaviate连接失败**
   ```bash
   # 检查服务状态
   docker-compose ps
   
   # 查看日志
   docker-compose logs weaviate
   
   # 重启服务
   docker-compose restart weaviate
   ```

3. **API密钥错误**
   ```bash
   # 检查环境变量
   echo $ZHIPUAI_API_KEY
   
   # 重新设置
   export ZHIPUAI_API_KEY=your_api_key
   ```

4. **内存不足**
   ```yaml
   # 调整分片配置
   fragmentation:
     max_chunk_size: 300  # 减小分片大小
     chunk_overlap: 30    # 减小重叠
   ```

---

## 📝 最新更新说明

### 1. 文本块过滤优化

**更新内容**：`doc_parser.py` 和 `xlsx_parser.py` 中的 `enhance_all_chunks` 函数添加了智能过滤机制。

**具体变化**：
- **只对分片文本块进行语义增强**：非分片的完整文本块不再生成描述和关键词
- **表格块始终增强**：所有表格块（`table_full` 和 `table_row`）都会进行语义增强
- **图片块不增强**：图片块不参与语义增强，避免不必要的API调用

**过滤逻辑**：
```python
chunks_to_enhance = [
    chunk
    for chunk in chunks
    if (
        # 表格块始终增强
        chunk.get("type") in ["table_full", "table_row"]
        or
        # 分片text块需要增强
        (
            chunk.get("type") == "text"
            and chunk.get("metadata", {}).get("is_fragment")
        )
    )
]
```

**优化效果**：
- 减少API调用次数，降低处理成本
- 提高处理效率，特别是对于大文档
- 保持语义增强的质量，只对需要的内容进行增强

### 2. 向量库Schema问题

**问题描述**：向量库schema中缺少 `context` 字段，导致存储时可能出现问题。

**影响范围**：
- 向量库创建时未包含 `context` 字段
- 存储分块数据时可能丢失上下文信息
- 查询时无法获取完整的上下文信息

**解决方案**：
1. **手动添加字段**：在Weaviate控制台中手动添加 `context` 字段
2. **更新Schema定义**：修改 `vector_service.py` 中的 `create_collection` 方法
3. **重新创建集合**：删除现有集合，重新创建包含完整字段的集合

**建议的Schema更新**：
```python
properties = [
    # ... 现有字段 ...
    {"name": "context", "dataType": "text", "description": "上下文信息"},
    # ... 其他字段 ...
]
```

### 3. 配置系统优化

**新增配置**：
- **视觉模型配置**：完整的VISION_CONFIG支持
- **表格处理配置**：更灵活的表格格式和分块策略
- **分片配置**：支持上下文重构和重叠设置

**配置层次**：
1. **环境变量**：`.env` 文件中的基础配置
2. **YAML配置**：`config/config.yaml` 中的系统配置
3. **代码配置**：运行时动态配置

### 4. 图片处理增强

**新增功能**：
- **图片定位策略**：支持inline、placeholder_replace、append_end三种模式
- **表格图片附着**：支持separate_block、merge_into_row、merge_into_table三种模式
- **上下文收集**：自动收集图片周围的文本上下文
- **视觉分析**：支持图片语义分析和关键词提取

**配置选项**：
```yaml
image_processing:
  enabled: true
  storage_path: "storage/images"
  image_position_strategy: "inline"
  table_image_attach_mode: "separate_block"
```

### 5. 问答系统改进

**功能增强**：
- **交互式问答**：新增 `QADemo` 类支持交互式问答
- **答案来源追踪**：提供详细的答案来源信息
- **相似度分数**：显示检索结果的相似度分数
- **批量问答**：支持批量问题处理

**使用示例**：
```python
from tests.qa_demo import QADemo

demo = QADemo()
await demo.interactive_qa()  # 交互式问答
await demo.batch_qa_demo()   # 批量问答演示
```

### 6. 性能优化

**优化措施**：
- **智能过滤**：减少不必要的API调用
- **批量处理**：支持批量文档处理和向量化
- **缓存机制**：支持LLM和视觉模型的缓存
- **并发控制**：可配置的并发数量限制

**配置参数**：
```bash
# 性能相关配置
MAX_ASYNC=4                    # 最大并发数
VISION_MAX_CONCURRENT=5        # 视觉模型最大并发数
ENABLE_LLM_CACHE=false         # LLM缓存开关
VISION_CACHE_ENABLED=true      # 视觉模型缓存开关
```

---

## 📚 总结

TableParser 系统提供了完整的文档解析、向量化和智能问答解决方案。通过合理的配置和优化，可以实现高效的文档处理和智能检索功能。

**关键配置点**：
- **LLM配置**: 影响语义增强和答案生成质量
- **嵌入模型配置**: 影响向量化效果和检索精度
- **分片配置**: 影响处理效率和存储空间
- **Docker配置**: 影响服务稳定性和性能
- **图片处理配置**: 影响图片功能的启用和策略

**最新优化**：
- 智能文本块过滤，减少API调用成本
- 完整的视觉模型配置支持
- 增强的图片处理功能
- 改进的问答系统体验
- 优化的性能配置

通过本文档的指导，您可以快速部署和使用TableParser系统，实现智能文档处理和分析功能。

---

## 📝 最新更新说明

### 1. 文本块过滤优化

**更新内容**：`doc_parser.py` 和 `xlsx_parser.py` 中的 `enhance_all_chunks` 函数添加了智能过滤机制。

**具体变化**：
- **只对分片文本块进行语义增强**：非分片的完整文本块不再生成描述和关键词
- **表格块始终增强**：所有表格块（`table_full` 和 `table_row`）都会进行语义增强
- **图片块不增强**：图片块不参与语义增强，避免不必要的API调用

**过滤逻辑**：
```python
chunks_to_enhance = [
    chunk
    for chunk in chunks
    if (
        # 表格块始终增强
        chunk.get("type") in ["table_full", "table_row"]
        or
        # 分片text块需要增强
        (
            chunk.get("type") == "text"
            and chunk.get("metadata", {}).get("is_fragment")
        )
    )
]
```

**优化效果**：
- 减少API调用次数，降低处理成本
- 提高处理效率，特别是对于大文档
- 保持语义增强的质量，只对需要的内容进行增强

### 2. 向量库Schema问题

**问题描述**：向量库schema中缺少 `context` 字段，导致存储时可能出现问题。

**影响范围**：
- 向量库创建时未包含 `context` 字段
- 存储分块数据时可能丢失上下文信息
- 查询时无法获取完整的上下文信息

**解决方案**：
1. **手动添加字段**：在Weaviate控制台中手动添加 `context` 字段
2. **更新Schema定义**：修改 `vector_service.py` 中的 `create_collection` 方法
3. **重新创建集合**：删除现有集合，重新创建包含完整字段的集合

**建议的Schema更新**：
```python
properties = [
    # ... 现有字段 ...
    {"name": "context", "dataType": "text", "description": "上下文信息"},
    # ... 其他字段 ...
]
```

### 3. 配置系统优化

**新增配置**：
- **视觉模型配置**：完整的VISION_CONFIG支持
- **表格处理配置**：更灵活的表格格式和分块策略
- **分片配置**：支持上下文重构和重叠设置

**配置层次**：
1. **环境变量**：`.env` 文件中的基础配置
2. **YAML配置**：`config/config.yaml` 中的系统配置
3. **代码配置**：运行时动态配置

### 4. 图片处理增强

**新增功能**：
- **图片定位策略**：支持inline、placeholder_replace、append_end三种模式
- **表格图片附着**：支持separate_block、merge_into_row、merge_into_table三种模式
- **上下文收集**：自动收集图片周围的文本上下文
- **视觉分析**：支持图片语义分析和关键词提取

**配置选项**：
```yaml
image_processing:
  enabled: true
  storage_path: "storage/images"
  image_position_strategy: "inline"
  table_image_attach_mode: "separate_block"
```

### 5. 问答系统改进

**功能增强**：
- **交互式问答**：新增 `QADemo` 类支持交互式问答
- **答案来源追踪**：提供详细的答案来源信息
- **相似度分数**：显示检索结果的相似度分数
- **批量问答**：支持批量问题处理

**使用示例**：
```python
from tests.qa_demo import QADemo

demo = QADemo()
await demo.interactive_qa()  # 交互式问答
await demo.batch_qa_demo()   # 批量问答演示
```

### 6. 性能优化

**优化措施**：
- **智能过滤**：减少不必要的API调用
- **批量处理**：支持批量文档处理和向量化
- **缓存机制**：支持LLM和视觉模型的缓存
- **并发控制**：可配置的并发数量限制

**配置参数**：
```bash
# 性能相关配置
MAX_ASYNC=4                    # 最大并发数
VISION_MAX_CONCURRENT=5        # 视觉模型最大并发数
ENABLE_LLM_CACHE=false         # LLM缓存开关
VISION_CACHE_ENABLED=true      # 视觉模型缓存开关
```

---

## 📚 总结

TableParser 系统提供了完整的文档解析、向量化和智能问答解决方案。通过合理的配置和优化，可以实现高效的文档处理和智能检索功能。

**关键配置点**：
- **LLM配置**: 影响语义增强和答案生成质量
- **嵌入模型配置**: 影响向量化效果和检索精度
- **分片配置**: 影响处理效率和存储空间
- **Docker配置**: 影响服务稳定性和性能
- **图片处理配置**: 影响图片功能的启用和策略

**最新优化**：
- 智能文本块过滤，减少API调用成本
- 完整的视觉模型配置支持
- 增强的图片处理功能
- 改进的问答系统体验
- 优化的性能配置

通过本文档的指导，您可以快速部署和使用TableParser系统，实现智能文档处理和分析功能。
